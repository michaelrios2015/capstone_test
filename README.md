## ðŸ“‚ Project Structure

```
project-root/
â”‚
â”œâ”€â”€ biz_day/ # Entry points for each "business day" workflow
â”‚ â”œâ”€â”€ first.py
â”‚ â”œâ”€â”€ fourth.py
â”‚ â””â”€â”€ ...
â”‚
â”œâ”€â”€ data_parsing/ # Core functions for data processing
â”‚ â”œâ”€â”€ cpr4th.py # calculates speeds for the 4th business day, we will have many more of these type of functions
â”‚ â””â”€â”€ ...
â”‚ â”œâ”€â”€ davids/ # Scripts with calculation logic
â”‚ â”‚ â”œâ”€â”€ cprs_final.py
â”‚ â”‚ â””â”€â”€ ...
â”‚ â”‚
â”‚ â”œâ”€â”€ db_loader/ # Database loading scripts
â”‚ â”‚ â”œâ”€â”€ a bunch more sub folders
â”‚ â”‚ â””â”€â”€ ...
â”‚ â”‚
â”‚ â”œâ”€â”€ ginnie_extract/ # File download automation (Selenium, etc.)
â”‚ â”‚ â”œâ”€â”€ gm_extractor.py
â”‚ â”‚ â””â”€â”€ ...
â”‚ â”‚
â”‚ â””â”€â”€ local_parser/ # Extract/clean raw data from downloaded files
â”‚ â”œâ”€â”€ pools.py
â”‚ â””â”€â”€ ...
â”‚
â””â”€â”€ README.md # Project documentation
```

---

## ðŸš€ Usage

1. **Run a business day workflow**

   Each script in `biz_day/` represents a full end-to-end workflow for a specific reporting/business day.
   Example:

   ```
   python biz_day/sixth.py
   ```

This will:

- Download the necessary Ginnie Mae files
- Parse and extract the required data
- Perform calculations (e.g., CPR, SMM, prepayment metrics)
- Load results into the database

---

## ðŸ”§ Components

### 1. **Business Day Scripts (`biz_day/`)**

- Contain **top-level functions** that can be run directly.
- Serve as orchestration points â€” they call into parsing, downloading, and loading modules.

### 2. **Data Parsing (`data_parsing/`)**

- **`cpr4th.py`** â€” an example of a main entry for a parsing function, in this case it calculates the cpr speed on the 4th business day.
- Subfolders:

  - **`davids/`** â€” numerical/statistical calculations on parsed data.
  - **`db_loader/`** â€” database integration (e.g., insert/update logic).
  - **`ginnie_extract/`** â€” automated file download via Selenium and other methods.
  - **`local_parser/`** â€” logic for cleaning and structuring raw datasets.

---

## ðŸ›  Dependencies

- **Python 3.x**
- **Selenium** (for automated downloads)
- **Pandas / NumPy** (data wrangling & calculations)
- **Psycopg2** (for loading into a SQL database)

---

## ðŸ“Œ Notes

- The **biz_day scripts** are designed to be standalone.
- Supporting functions live in **data_parsing** and its submodules.
- Code is modular, so new data sources or calculations can be added by extending the relevant subfolder.

---

```



```
